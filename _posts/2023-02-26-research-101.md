---
title: Research 101!
date: 2023-02-26 15:00:00 +/-TTTT
categories: [research,data-science]
tags: [deep-learning,machine-learning,research]
---


![image](/assets/img/research_101_blog/reserach1.webp)



I've been reading ***Deep Learning*** and ***Quantum Computing*** Research Papers for a while now. Math never scares me; instead, it draws me in. I find equations and math beautiful and fascinating, but I believe I might have developed an unhealthy obsession with them, going down rabbit holes just to get to the bottom of it, often losing sight of why I started reading the paper!  üò•

It was obvious that I needed better tips and strategies to help me read research papers more efficiently and effectively. And it was none other than [Prof. Andrew Ng](https://www.andrewng.org/) who would guide me on this.

## **Pro Tip: ‚Äú*To be the best, learn from the best!‚Äù***

Here‚Äôs a summary of how to read research papers efficiently and effectively, by **[Prof. Andrew Ng](https://www.andrewng.org/)**


| ![image](/assets/img/research_101_blog/andrew_ng_cs229.jpg) | 
|:--:| 
| *Andew Ng, Stanfors CS229: Machine Learning -Autumn2018* |



## **0. Getting Started**

Pick an area of interest (e.g., speech processing) and compile a list of papers (which can also include medium/blogs). Quickly scan around 10% of all papers and pick a few relevant and interesting ones. Skip the rest. (You can always find more papers from citations!)

####  **NOTE: Reading *20-50 papers* will give you a basic understanding of the area, whereas reading *50-100 papers* will give you a very good understanding of the area.**

## **1. Reading one Paper**

Always take multiple passes through the paper.
* 1st pass: Read the title, abstracts, figures 
* 2nd pass: Go through the Introduction, conclusion, and Figures & Skim through the rest
* 3rd pass: Read the rest but skip the math
* 4th pass: Read the whole paper but skip parts that don‚Äôt make sense.

*Depending on the level of understanding you require, you may take as many passes as necessary.*

## **2. Always try answering these questions** (after reading the paper)

* What did the authors try to accomplish?
* What are the key elements of the approach?
* What can you use yourself?
* What other references do you need to follow?

## **3. More In-Depth Understanding**

### **- Dealing with Math** 

Sit down & read through the math, take detailed notes, and try to derive (from scratch) the math/algorithm.

### **- Dealing with Code**

Lightweight: download and run their open-source code (assuming they have it).
Deeper: reimplement their code from scratch.

## **4. Where to Find papers:**
- Twitter
- ML Subreddit: r/MachineLearning
- Top ML Conferences: NeurIPS , ICML , ICLR 
- ArXiv Sanity 
- Friends / Online Community

## **5. General Advice:**


# **‚ÄúLearn steadily rather than in short bursts for longevity.‚Äú                    -- [Prof. Andrew Ng](https://www.andrewng.org/)**




Cultivate the habit of reading **2 or 3 papers per week** for a year. Most importantly, maintain your streak.



{% include embed/{youtube}.html id='{733m6qBH-jI}' %}

These tips are shared in ***[Lecture 8](https://youtu.be/733m6qBH-jI)*** of the **Stanford graduate course CS230** taught by [Prof. Andrew Ng](https://www.andrewng.org/). *The second part of the same lecture also includes Carrer Advice.* 

<div style="text-align: center;">

| ![image](/assets/img/research_101_blog/cs230.png) | 
|:--:| 
| *Stanford CS230: Deep Learning* |
</div>


## ***[Link for CS230 Playlist](https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb)*** 

These lecture videos are best viewed along with the Deep Learning Specialization taught by Andrew Ng, offered on Coursera by DeepLearning.AI.


